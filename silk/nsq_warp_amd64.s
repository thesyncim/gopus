#include "textflag.h"

// func warpedARFeedback24(sAR2Q14 *[24]int32, diffQ14 int32, arShpQ13 []int16, warpQ16 int32) int32
//
// Go ABI0 frame layout on AMD64:
//   sAR2Q14+0(FP)        *[24]int32
//   diffQ14+8(FP)        int32
//   arShpQ13_base+16(FP) *int16
//   arShpQ13_len+24(FP)  int
//   arShpQ13_cap+32(FP)  int
//   warpQ16+40(FP)       int32
//   ret+48(FP)           int32
//
// Register allocation:
//   SI  = sAR2Q14 base pointer
//   DI  = arShpQ13 base pointer
//   R8  = warpQ16 (sign-extended to 64-bit)
//   AX  = accumulator (nARQ14)
//   BX  = tmp1
//   CX  = tmp2
//   DX  = scratch (loads, products)
//   R9  = scratch
//   R10 = scratch
TEXT ·warpedARFeedback24(SB), NOSPLIT|NOFRAME, $0-52
	MOVQ	sAR2Q14+0(FP), SI
	MOVLQSX	diffQ14+8(FP), CX         // CX = tmp2 = diffQ14
	MOVQ	arShpQ13_base+16(FP), DI
	MOVLQSX	warpQ16+40(FP), R8         // R8 = warpQ16 sign-extended

	// Initial step:
	// tmp2 = diffQ14 + (sAR[0] * warp) >> 16
	// tmp1 = sAR[0] + ((sAR[1] - tmp2) * warp) >> 16
	MOVLQSX	(SI), BX                   // BX = sAR[0]
	MOVQ	BX, DX
	IMULQ	R8, DX                     // DX = sAR[0] * warp
	SARQ	$16, DX
	ADDL	DX, CX                     // tmp2 = diffQ14 + (sAR[0]*warp)>>16

	MOVLQSX	4(SI), DX                  // DX = sAR[1]
	SUBL	CX, DX                     // DX = sAR[1] - tmp2
	MOVLQSX	DX, DX                     // sign-extend after 32-bit SUB
	IMULQ	R8, DX
	SARQ	$16, DX
	ADDL	DX, BX                     // tmp1 = sAR[0] + ((sAR[1]-tmp2)*warp)>>16

	MOVL	CX, (SI)                   // sAR[0] = tmp2

	// acc = 12 + (tmp2 * arShpQ13[0]) >> 16
	MOVL	$12, AX
	MOVWQSX	(DI), DX                   // DX = arShpQ13[0]
	MOVLQSX	CX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

	// Macro: process one half-pair (odd tap j)
	// Input: BX=tmp1, CX=tmp2 (from prev)
	// Output: CX=new tmp2, BX unchanged
	// Then process even tap: BX=new tmp1, CX unchanged

// --- Pair j=2,3 ---
	MOVLQSX	4(SI), DX                  // DX = sAR[1]
	MOVLQSX	8(SI), R9                  // R9 = sAR[2]
	SUBL	BX, R9                     // R9 = sAR[2] - tmp1
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, CX                     // tmp2 = sAR[1] + ((sAR[2]-tmp1)*warp)>>16
	MOVL	BX, 4(SI)                  // sAR[1] = tmp1
	MOVWQSX	2(DI), DX
	MOVLQSX	BX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

	MOVLQSX	8(SI), DX
	MOVLQSX	12(SI), R9
	SUBL	CX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, BX                     // tmp1 = sAR[2] + ((sAR[3]-tmp2)*warp)>>16
	MOVL	CX, 8(SI)                  // sAR[2] = tmp2
	MOVWQSX	4(DI), DX
	MOVLQSX	CX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

// --- Pair j=4,5 ---
	MOVLQSX	12(SI), DX
	MOVLQSX	16(SI), R9
	SUBL	BX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, CX
	MOVL	BX, 12(SI)
	MOVWQSX	6(DI), DX
	MOVLQSX	BX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

	MOVLQSX	16(SI), DX
	MOVLQSX	20(SI), R9
	SUBL	CX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, BX
	MOVL	CX, 16(SI)
	MOVWQSX	8(DI), DX
	MOVLQSX	CX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

// --- Pair j=6,7 ---
	MOVLQSX	20(SI), DX
	MOVLQSX	24(SI), R9
	SUBL	BX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, CX
	MOVL	BX, 20(SI)
	MOVWQSX	10(DI), DX
	MOVLQSX	BX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

	MOVLQSX	24(SI), DX
	MOVLQSX	28(SI), R9
	SUBL	CX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, BX
	MOVL	CX, 24(SI)
	MOVWQSX	12(DI), DX
	MOVLQSX	CX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

// --- Pair j=8,9 ---
	MOVLQSX	28(SI), DX
	MOVLQSX	32(SI), R9
	SUBL	BX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, CX
	MOVL	BX, 28(SI)
	MOVWQSX	14(DI), DX
	MOVLQSX	BX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

	MOVLQSX	32(SI), DX
	MOVLQSX	36(SI), R9
	SUBL	CX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, BX
	MOVL	CX, 32(SI)
	MOVWQSX	16(DI), DX
	MOVLQSX	CX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

// --- Pair j=10,11 ---
	MOVLQSX	36(SI), DX
	MOVLQSX	40(SI), R9
	SUBL	BX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, CX
	MOVL	BX, 36(SI)
	MOVWQSX	18(DI), DX
	MOVLQSX	BX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

	MOVLQSX	40(SI), DX
	MOVLQSX	44(SI), R9
	SUBL	CX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, BX
	MOVL	CX, 40(SI)
	MOVWQSX	20(DI), DX
	MOVLQSX	CX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

// --- Pair j=12,13 ---
	MOVLQSX	44(SI), DX
	MOVLQSX	48(SI), R9
	SUBL	BX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, CX
	MOVL	BX, 44(SI)
	MOVWQSX	22(DI), DX
	MOVLQSX	BX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

	MOVLQSX	48(SI), DX
	MOVLQSX	52(SI), R9
	SUBL	CX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, BX
	MOVL	CX, 48(SI)
	MOVWQSX	24(DI), DX
	MOVLQSX	CX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

// --- Pair j=14,15 ---
	MOVLQSX	52(SI), DX
	MOVLQSX	56(SI), R9
	SUBL	BX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, CX
	MOVL	BX, 52(SI)
	MOVWQSX	26(DI), DX
	MOVLQSX	BX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

	MOVLQSX	56(SI), DX
	MOVLQSX	60(SI), R9
	SUBL	CX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, BX
	MOVL	CX, 56(SI)
	MOVWQSX	28(DI), DX
	MOVLQSX	CX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

// --- Pair j=16,17 ---
	MOVLQSX	60(SI), DX
	MOVLQSX	64(SI), R9
	SUBL	BX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, CX
	MOVL	BX, 60(SI)
	MOVWQSX	30(DI), DX
	MOVLQSX	BX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

	MOVLQSX	64(SI), DX
	MOVLQSX	68(SI), R9
	SUBL	CX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, BX
	MOVL	CX, 64(SI)
	MOVWQSX	32(DI), DX
	MOVLQSX	CX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

// --- Pair j=18,19 ---
	MOVLQSX	68(SI), DX
	MOVLQSX	72(SI), R9
	SUBL	BX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, CX
	MOVL	BX, 68(SI)
	MOVWQSX	34(DI), DX
	MOVLQSX	BX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

	MOVLQSX	72(SI), DX
	MOVLQSX	76(SI), R9
	SUBL	CX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, BX
	MOVL	CX, 72(SI)
	MOVWQSX	36(DI), DX
	MOVLQSX	CX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

// --- Pair j=20,21 ---
	MOVLQSX	76(SI), DX
	MOVLQSX	80(SI), R9
	SUBL	BX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, CX
	MOVL	BX, 76(SI)
	MOVWQSX	38(DI), DX
	MOVLQSX	BX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

	MOVLQSX	80(SI), DX
	MOVLQSX	84(SI), R9
	SUBL	CX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, BX
	MOVL	CX, 80(SI)
	MOVWQSX	40(DI), DX
	MOVLQSX	CX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

// --- Pair j=22,23 (last pair) ---
	MOVLQSX	84(SI), DX
	MOVLQSX	88(SI), R9
	SUBL	BX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, CX
	MOVL	BX, 84(SI)                // sAR[21] = tmp1
	MOVWQSX	42(DI), DX
	MOVLQSX	BX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

	MOVLQSX	88(SI), DX
	MOVLQSX	92(SI), R9
	SUBL	CX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, BX                     // tmp1 = sAR[22] + ((sAR[23]-tmp2)*warp)>>16
	MOVL	CX, 88(SI)                // sAR[22] = tmp2
	MOVWQSX	44(DI), DX
	MOVLQSX	CX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

	// Final: sAR[23] = tmp1, acc += (tmp1 * arShpQ13[23]) >> 16
	MOVL	BX, 92(SI)
	MOVWQSX	46(DI), DX
	MOVLQSX	BX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

	MOVL	AX, ret+48(FP)
	RET

// func warpedARFeedback16(sAR2Q14 *[24]int32, diffQ14 int32, arShpQ13 []int16, warpQ16 int32) int32
TEXT ·warpedARFeedback16(SB), NOSPLIT|NOFRAME, $0-52
	MOVQ	sAR2Q14+0(FP), SI
	MOVLQSX	diffQ14+8(FP), CX
	MOVQ	arShpQ13_base+16(FP), DI
	MOVLQSX	warpQ16+40(FP), R8

	// Initial step
	MOVLQSX	(SI), BX
	MOVQ	BX, DX
	IMULQ	R8, DX
	SARQ	$16, DX
	ADDL	DX, CX

	MOVLQSX	4(SI), DX
	SUBL	CX, DX
	MOVLQSX	DX, DX
	IMULQ	R8, DX
	SARQ	$16, DX
	ADDL	DX, BX

	MOVL	CX, (SI)

	MOVL	$8, AX
	MOVWQSX	(DI), DX
	MOVLQSX	CX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

// --- Pair j=2,3 ---
	MOVLQSX	4(SI), DX
	MOVLQSX	8(SI), R9
	SUBL	BX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, CX
	MOVL	BX, 4(SI)
	MOVWQSX	2(DI), DX
	MOVLQSX	BX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

	MOVLQSX	8(SI), DX
	MOVLQSX	12(SI), R9
	SUBL	CX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, BX
	MOVL	CX, 8(SI)
	MOVWQSX	4(DI), DX
	MOVLQSX	CX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

// --- Pair j=4,5 ---
	MOVLQSX	12(SI), DX
	MOVLQSX	16(SI), R9
	SUBL	BX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, CX
	MOVL	BX, 12(SI)
	MOVWQSX	6(DI), DX
	MOVLQSX	BX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

	MOVLQSX	16(SI), DX
	MOVLQSX	20(SI), R9
	SUBL	CX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, BX
	MOVL	CX, 16(SI)
	MOVWQSX	8(DI), DX
	MOVLQSX	CX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

// --- Pair j=6,7 ---
	MOVLQSX	20(SI), DX
	MOVLQSX	24(SI), R9
	SUBL	BX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, CX
	MOVL	BX, 20(SI)
	MOVWQSX	10(DI), DX
	MOVLQSX	BX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

	MOVLQSX	24(SI), DX
	MOVLQSX	28(SI), R9
	SUBL	CX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, BX
	MOVL	CX, 24(SI)
	MOVWQSX	12(DI), DX
	MOVLQSX	CX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

// --- Pair j=8,9 ---
	MOVLQSX	28(SI), DX
	MOVLQSX	32(SI), R9
	SUBL	BX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, CX
	MOVL	BX, 28(SI)
	MOVWQSX	14(DI), DX
	MOVLQSX	BX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

	MOVLQSX	32(SI), DX
	MOVLQSX	36(SI), R9
	SUBL	CX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, BX
	MOVL	CX, 32(SI)
	MOVWQSX	16(DI), DX
	MOVLQSX	CX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

// --- Pair j=10,11 ---
	MOVLQSX	36(SI), DX
	MOVLQSX	40(SI), R9
	SUBL	BX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, CX
	MOVL	BX, 36(SI)
	MOVWQSX	18(DI), DX
	MOVLQSX	BX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

	MOVLQSX	40(SI), DX
	MOVLQSX	44(SI), R9
	SUBL	CX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, BX
	MOVL	CX, 40(SI)
	MOVWQSX	20(DI), DX
	MOVLQSX	CX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

// --- Pair j=12,13 ---
	MOVLQSX	44(SI), DX
	MOVLQSX	48(SI), R9
	SUBL	BX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, CX
	MOVL	BX, 44(SI)
	MOVWQSX	22(DI), DX
	MOVLQSX	BX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

	MOVLQSX	48(SI), DX
	MOVLQSX	52(SI), R9
	SUBL	CX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, BX
	MOVL	CX, 48(SI)
	MOVWQSX	24(DI), DX
	MOVLQSX	CX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

// --- Pair j=14, final tap 15 ---
	MOVLQSX	52(SI), DX
	MOVLQSX	56(SI), R9
	SUBL	BX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, CX
	MOVL	BX, 52(SI)
	MOVWQSX	26(DI), DX
	MOVLQSX	BX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

	MOVLQSX	56(SI), DX
	MOVLQSX	60(SI), R9
	SUBL	CX, R9
	MOVLQSX	R9, R9
	IMULQ	R8, R9
	SARQ	$16, R9
	ADDL	R9, DX
	MOVL	DX, BX
	MOVL	CX, 56(SI)
	MOVWQSX	28(DI), DX
	MOVLQSX	CX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

	// Final: sAR[15] = tmp1, acc += (tmp1 * arShpQ13[15]) >> 16
	MOVL	BX, 60(SI)
	MOVWQSX	30(DI), DX
	MOVLQSX	BX, R9
	IMULQ	DX, R9
	SARQ	$16, R9
	ADDL	R9, AX

	MOVL	AX, ret+48(FP)
	RET
